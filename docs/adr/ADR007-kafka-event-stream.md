# ADR007: Kafka Event Stream

### Status
Accepted

---

### Context
정책 평가 결과(decision log)는 디버깅과 분석을 위해 반드시 저장되어야 하며,
조회 성능과 운영 신뢰도를 위해 누락 없이 수집되는 것이 중요하다.

현재 수집 구조는 수신 서버가 로그를 받아
동기 저장 방식으로 데이터베이스에 적재하는 형태를 갖고 있다.

이 방식은 초기 구현이 단순하고 빠르게 검증할 수 있다는 장점이 있으나,
확장 단계에서 다음 한계를 갖는다.

- 수신 서버 재시작/장애 시, 메모리 큐에 적재된 로그가 유실될 수 있음
- 로그 저장 경로(DB) 외에, 동일 로그를 다른 용도로 활용하기 어려움
  - 예: 실시간 모니터링, 정책 통계 집계, OpenSearch 적재, 알림/탐지 파이프라인 등

OPA 인스턴스가 늘어나면 로그 유입량이 증가하고,
저장 지연/장애에 대응하기 위한 비동기 처리 및 관측 경로 보호가 필요해진다.

---

### Problem
메모리 큐 기반 비동기 저장은 다음 문제를 완전히 해결하기 어렵다.

- 프로세스 재시작 시 큐 유실로 인한 관측 신뢰도 저하
- 수집 서버를 스케일아웃 할수록, 인스턴스별 큐 상태가 달라지고 운영 복잡도가 증가
- 동일 로그를 다른 소비자가 활용하려면 별도 연동을 추가해야 하며,
  이후 기능(검색/통계/탐지)이 늘어날수록 결합도가 커짐

decision log는 단일 DB 적재만으로 끝나는 데이터가 아니라
향후 다양한 목적(조회/분석/탐지/검색)으로 재사용될 가능성이 높으며,
이를 안정적으로 전달·보관할 이벤트 스트림 계층이 필요

---

### Alternatives

#### 1. 메모리 큐 기반 비동기 저장 유지
수신 서버 내부 큐를 bounded로 구성하고, backpressure/drop 정책으로 폭주를 제어

- 초기 구현은 가장 단순
- 재시작 시 유실 문제를 근본적으로 해결할 수 없음
- 다중 소비(팬아웃) 요구가 생길 때마다 연동이 누적됨

#### 2. 파일 기반 스풀링(Spool) 도입
DB 저장 전 단계에서 로컬 파일로 임시 적재한 뒤, 재시작 후 재처리

- 유실은 줄일 수 있음
- 스케일아웃/다중 소비 구조로 확장하기 어려움
- 운영 및 장애 처리 로직이 애플리케이션에 계속 쌓임

#### 3. Kafka 도입
수신 서버가 decision log를 Kafka 토픽에 발행하고, DB 적재 및 추가 기능은 consumer로 분리

- 내구성 있는 로그(디스크 기반)로 재시작/장애 시 유실을 줄임
- consumer group을 통해 동일 이벤트를 여러 소비자가 독립적으로 처리 가능

---

### Decision
대안 3을 선택

decision log 수집 파이프라인의 안정성과 확장성을 확보하기 위해 Kafka를 이벤트 스트림 계층으로 도입

- 수신 서버 재시작/장애 상황에서도 DB 적재 전 단계에서 decision log가 유실되지 않도록 내구성 있는 버퍼를 제공
- decision log를 "재사용 가능한 이벤트 스트림"으로 정의하여, 향후 다양한 소비자를 독립적으로 추가 가능하게 함

---

### Consequences
- 수집 서버 재시작/장애 시에도 decision log 유실 가능성을 크게 낮춤
- DB 적재와 다른 소비 기능을 분리하여 기능 추가 시 결합도를 낮추고 확장성을 확보
- 처리량 증가 시, consumer 확장(파티션/컨슈머 수 조절)로 대응 가능

트레이드 오프:
- Kafka 운영 비용과 복잡도가 추가됨
- 토픽 파티션 설계, 보관 기간(retention), 모니터링 및 장애 대응 등 운영 관점의 설계가 필요
